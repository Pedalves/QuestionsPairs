{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Question Pairs\n",
    "\n",
    "### Motivação\n",
    "\n",
    "Um dos desafios conhecidos dos chatbots é o fato de diferentes pessoas escreverem as mesmas sentenças de maneiras distintas. Este fato acarreta em dois grandes problemas, o primeiro é a necessidade de um grande volume de informações e exemplos, para tentar cobrir o máximo formas distintas para uma mesma pergunta, e a frustração do usuário que não consegue ser entendido pelo fato de ter escrito de uma maneira diferente da esperada. Visto isso meu objetivo com este trabalho é reconhecer casos de perguntas com o mesmo propósito.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"badchatbot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pedro/anaconda3/envs/condaVENV/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import gensim.models.word2vec as word2vec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('resources/quora_duplicate_questions.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      "id              404290 non-null int64\n",
      "qid1            404290 non-null int64\n",
      "qid2            404290 non-null int64\n",
      "question1       404289 non-null object\n",
      "question2       404288 non-null object\n",
      "is_duplicate    404290 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>217243.942418</td>\n",
       "      <td>220955.655337</td>\n",
       "      <td>0.369198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116708.614503</td>\n",
       "      <td>157751.700002</td>\n",
       "      <td>159903.182629</td>\n",
       "      <td>0.482588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101072.250000</td>\n",
       "      <td>74437.500000</td>\n",
       "      <td>74727.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>192182.000000</td>\n",
       "      <td>197052.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303216.750000</td>\n",
       "      <td>346573.500000</td>\n",
       "      <td>354692.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>537932.000000</td>\n",
       "      <td>537933.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           qid1           qid2   is_duplicate\n",
       "count  404290.000000  404290.000000  404290.000000  404290.000000\n",
       "mean   202144.500000  217243.942418  220955.655337       0.369198\n",
       "std    116708.614503  157751.700002  159903.182629       0.482588\n",
       "min         0.000000       1.000000       2.000000       0.000000\n",
       "25%    101072.250000   74437.500000   74727.000000       0.000000\n",
       "50%    202144.500000  192182.000000  197052.000000       0.000000\n",
       "75%    303216.750000  346573.500000  354692.500000       1.000000\n",
       "max    404289.000000  537932.000000  537933.000000       1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f719599f2b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f71959b36a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['is_duplicate'].value_counts().plot(kind='bar', color=['blue', 'red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model\n",
    "\n",
    "O word2vec vetoriza cada palavra do corpus levando em consideração o contexto no qual é usada, deste modo palavras de contexto parecidos são espacialmente próximas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"linear-relationships.png\",width=800,height=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = u\"\"\n",
    "\n",
    "for question in df['question1']:\n",
    "    corpus_raw += str(question)\n",
    "    \n",
    "for question in df['question2']:\n",
    "    corpus_raw += str(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus contains 8,974,341 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n",
    "downsampling = 1e-3\n",
    "\n",
    "word2vec_model = word2vec.Word2Vec(\n",
    "    sg=1,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")\n",
    "\n",
    "word2vec_model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 96440\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", word2vec_model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32409518"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train(sentences=sentences, total_examples=word2vec_model.corpus_count, epochs=word2vec_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "\n",
    "word2vec_model.save(os.path.join(\"trained\", \"word2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec Model\n",
    "\n",
    "Caso já exista um modelo localmente, não existe a necessidade de um novo treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.Word2Vec.load(os.path.join(\"trained\", \"word2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hinduism', 0.6152031421661377),\n",
       " ('Christianity', 0.5793802738189697),\n",
       " ('atheism', 0.5729184150695801),\n",
       " ('Abrahamic', 0.5699256658554077),\n",
       " ('disproving', 0.5685814619064331),\n",
       " ('Islam', 0.5668637156486511),\n",
       " ('Buddhists', 0.5447323322296143),\n",
       " ('monotheistic', 0.5379245281219482),\n",
       " ('lame', 0.5344815850257874),\n",
       " ('religions', 0.5328493714332581)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar(\"religion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model\n",
    "\n",
    "\n",
    "A LSTM foi utilizada por 2 principais motivos. O primeiro diz respeito ao fato de LSTM ser uma RNN, o que permite uma entrada de tamanho variável, o que é perfeito para tratar perguntas de tamanhos diferentes. O segundo motivo, e mais importante, é o fato da LSTM guardar uma memória do que foi previamente passado como input, ou seja, a ordem das palavras importa, ‘cachorro mordeu o homem’ não é igual a ‘homem mordeu o cachorro’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lstm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200000\n",
    "max_sequence_length = 300\n",
    "batch_size = 100\n",
    "num_lstm = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df['question1'].astype(str) + df['question2'].astype(str))\n",
    "\n",
    "sequence1 = tokenizer.texts_to_sequences(df['question1'].astype(str))\n",
    "sequence2 = tokenizer.texts_to_sequences(df['question2'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pad_sequences(sequences=sequence1, maxlen=max_sequence_length)\n",
    "data2 = pad_sequences(sequences=sequence2, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(max_words, len(tokenizer.word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, num_features))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv.vocab:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words, num_features, weights=[embedding_matrix], \n",
    "                    trainable=False, input_length=max_sequence_length)\n",
    "\n",
    "lstm_layer = LSTM(num_lstm, dropout=0.2, recurrent_dropout=0.2)\n",
    "\n",
    "input1 = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "embedded1 = embedding_layer(input1)\n",
    "lstm1 = lstm_layer(embedded1)\n",
    "\n",
    "input2 = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "embedded2 = embedding_layer(input2)\n",
    "lstm2 = lstm_layer(embedded2)\n",
    "\n",
    "merged = concatenate([lstm1, lstm2])\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input1, input2], outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.DataFrame(data1)\n",
    "temp2 = pd.DataFrame(data2)\n",
    "temp = pd.concat([temp1, temp2], axis=1)\n",
    "temp['Y'] = df['is_duplicate']\n",
    "\n",
    "X = temp.iloc[:, :-1].values\n",
    "Y = temp.iloc[:, -1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80858, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:,300:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323432 samples, validate on 80858 samples\n",
      "Epoch 1/15\n",
      "323432/323432 [==============================] - 4074s 13ms/step - loss: 0.5137 - acc: 0.7488 - val_loss: 0.4987 - val_acc: 0.7588\n",
      "Epoch 2/15\n",
      "323432/323432 [==============================] - 4056s 13ms/step - loss: 0.4992 - acc: 0.7586 - val_loss: 0.4898 - val_acc: 0.7657\n",
      "Epoch 3/15\n",
      "323432/323432 [==============================] - 4048s 13ms/step - loss: 0.4902 - acc: 0.7647 - val_loss: 0.4810 - val_acc: 0.7719\n",
      "Epoch 4/15\n",
      "323432/323432 [==============================] - 4075s 13ms/step - loss: 0.4813 - acc: 0.7693 - val_loss: 0.4800 - val_acc: 0.7722\n",
      "Epoch 5/15\n",
      "323432/323432 [==============================] - 8915s 28ms/step - loss: 0.4757 - acc: 0.7740 - val_loss: 0.4734 - val_acc: 0.7778\n",
      "Epoch 6/15\n",
      "323432/323432 [==============================] - 4333s 13ms/step - loss: 0.4702 - acc: 0.7771 - val_loss: 0.4748 - val_acc: 0.7772\n",
      "Epoch 7/15\n",
      "323432/323432 [==============================] - 10343s 32ms/step - loss: 0.4653 - acc: 0.7810 - val_loss: 0.4720 - val_acc: 0.7798\n",
      "Epoch 8/15\n",
      "323432/323432 [==============================] - 7883s 24ms/step - loss: 0.4607 - acc: 0.7835 - val_loss: 0.4686 - val_acc: 0.7818\n",
      "Epoch 9/15\n",
      "323432/323432 [==============================] - 5890s 18ms/step - loss: 0.4581 - acc: 0.7855 - val_loss: 0.4672 - val_acc: 0.7833\n",
      "Epoch 10/15\n",
      "323432/323432 [==============================] - 4204s 13ms/step - loss: 0.4547 - acc: 0.7880 - val_loss: 0.4671 - val_acc: 0.7837\n",
      "Epoch 11/15\n",
      "323432/323432 [==============================] - 4185s 13ms/step - loss: 0.4520 - acc: 0.7891 - val_loss: 0.4663 - val_acc: 0.7815\n",
      "Epoch 12/15\n",
      "323432/323432 [==============================] - 11275s 35ms/step - loss: 0.4499 - acc: 0.7902 - val_loss: 0.4667 - val_acc: 0.7818\n",
      "Epoch 13/15\n",
      "323432/323432 [==============================] - 4721s 15ms/step - loss: 0.4476 - acc: 0.7913 - val_loss: 0.4648 - val_acc: 0.7859\n",
      "Epoch 14/15\n",
      "323432/323432 [==============================] - 4618s 14ms/step - loss: 0.4452 - acc: 0.7931 - val_loss: 0.4642 - val_acc: 0.7847\n",
      "Epoch 15/15\n",
      "323432/323432 [==============================] - 37926s 117ms/step - loss: 0.4432 - acc: 0.7945 - val_loss: 0.4636 - val_acc: 0.7830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f033d75c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model.fit([X_train[:,:300], X_train[:,300:]], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=([X_test[:,:300], X_test[:,300:]], Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_condaVENV",
   "language": "python",
   "name": "python3_condavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
